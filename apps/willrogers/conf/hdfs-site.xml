<?xml version="1.0" encoding="UTF-8"?>

<!--Autogenerated by Cloudera CM on 2014-01-20T20:44:15.031Z-->
<configuration>
  <property>
    <name>dfs.nameservices</name>
    <value>nameservice1</value>
  </property>
  <property>
    <name>dfs.client.failover.proxy.provider.nameservice1</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
  <property>
    <name>dfs.ha.namenodes.nameservice1</name>
    <value>namenode678,namenode38</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.nameservice1.namenode678</name>
    <value>jobs-dev-hnn2.klout:8020</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address.nameservice1.namenode678</name>
    <value>jobs-dev-hnn2.klout:8022</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.nameservice1.namenode678</name>
    <value>jobs-dev-hnn2.klout:50070</value>
  </property>
  <property>
    <name>dfs.namenode.https-address.nameservice1.namenode678</name>
    <value>jobs-dev-hnn2.klout:50470</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.nameservice1.namenode38</name>
    <value>jobs-dev-hnn1.klout:8020</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address.nameservice1.namenode38</name>
    <value>jobs-dev-hnn1.klout:8022</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.nameservice1.namenode38</name>
    <value>jobs-dev-hnn1.klout:50070</value>
  </property>
  <property>
    <name>dfs.namenode.https-address.nameservice1.namenode38</name>
    <value>jobs-dev-hnn1.klout:50470</value>
  </property>
  <!--'dfs.replication', originally set to '3' (non-final), is overridden below by a safety valve-->
  <property>
    <name>dfs.blocksize</name>
    <value>268435456</value>
  </property>
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>true</value>
  </property>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>022</value>
  </property>
  <!--'dfs.client.read.shortcircuit', originally set to 'false' (non-final), is overridden below by a safety valve-->
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hdfs-sockets/dn</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit.skip.checksum</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.domain.socket.data.traffic</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://nameservice1</value>
  </property>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://jobs-dev-hnn:8020</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/tmp/hadoop</value>
  </property>
  <property>
    <name>fs.trash.interval</name>
    <value>15</value>
  </property>
  <property>
    <name>topology.script.file.name</name>
    <value>/etc/hadoop/conf/rack.sh</value>
  </property>
  <property>
    <name>local.cache.size</name>
    <value>1073741824</value>
  </property>
  <property>
    <name>io.compression.codecs</name>
    <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</value>
  </property>
  <property>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
  </property>
  <property>
    <name>io.file.buffer.size</name>
    <value>65536</value>
  </property>
  <property>
    <name>hadoop.proxyuser.oozie.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.oozie.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>webinterface.private.actions</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.name.dir</name>
    <value>/data1/hadoop/dfs/name,/data2/hadoop/dfs/name,/data3/hadoop/dfs/name,/data4/hadoop/dfs/name,/data5/hadoop/dfs/name,/data6/hadoop/dfs/name,/data7/hadoop/dfs/name</value>
  </property>
  <property>
    <name>dfs.data.dir</name>
    <value>/data1/hadoop/dfs/data,/data2/hadoop/dfs/data,/data3/hadoop/dfs/data,/data4/hadoop/dfs/data,/data5/hadoop/dfs/data,/data6/hadoop/dfs/data,/data7/hadoop/dfs/data</value>
  </property>
  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>64</value>
  </property>
  <property>
    <name>dfs.block.size</name>
    <value>268435456</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>755</value>
  </property>
  <property>
    <name>dfs.datanode.du.reserved</name>
    <value>10737418240</value>
  </property>
  <property>
    <name>dfs.datanode.socket.write.timeout</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.datanode.handler.count</name>
    <value>100</value>
  </property>
  <property>
    <name>dfs.datanode.max.xcievers</name>
    <value>4096</value>
  </property>
  <property>
    <name>dfs.balance.bandwidthPerSec</name>
    <value>39321600</value>
  </property>
  <property>
    <name>dfs.namenode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.datanode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.thrift.address</name>
    <value>0.0.0.0:9090</value>
  </property>
  <property>
    <name>dfs.block.local-path-access.user</name>
    <value>hbase</value>
  </property>
  <property>
    <name>mapred.map.output.compression.codec</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
  </property>
  <property>
    <name>mapred.output.compression.codec</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
  </property>
</configuration>
